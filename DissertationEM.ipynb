{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add02b35-a62f-436e-a342-bb4426c083b1",
   "metadata": {},
   "source": [
    "1. Checking the SFT datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da021a99-fb88-4951-be5d-e74b5fac7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('SFS_metadata.csv')\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de14cb9-205e-42fb-bde4-65e965a7ee08",
   "metadata": {},
   "source": [
    "2. Clean key columns (convert timestamps, drop/clean irrelevant columns, standardise tags, extract location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426bcaf-f377-4b6a-b3ab-f6b24062b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_clean_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and clean the fashion dataset.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df = df.dropna(subset=['time', 'tags'])\n",
    "\n",
    "    df['time'] = pd.to_datetime(df['time'].str.replace('Updated on ', ''), errors='coerce')\n",
    "    df = df.dropna(subset=['time'])\n",
    "\n",
    "    df['tags'] = df['tags'].str.lower().str.strip(',')\n",
    "\n",
    "    df['styles'] = df['styles'].fillna('').str.lower().str.strip(',')\n",
    "\n",
    "    df['location'] = df['location'].str.strip().str.title()\n",
    "\n",
    "    return df\n",
    "\n",
    "def explode_tags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Explode the tags column so each tag has its own row.\"\"\"\n",
    "    df_exploded = df.assign(tag=df['tags'].str.split(',')).explode('tag')\n",
    "    df_exploded['tag'] = df_exploded['tag'].str.strip()\n",
    "    return df_exploded\n",
    "\n",
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add month-level time features for grouping.\"\"\"\n",
    "    df['month'] = df['time'].dt.to_period('M').dt.to_timestamp()\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"SFS_metadata.csv\"\n",
    "    df = load_and_clean_data(file_path)\n",
    "    df = explode_tags(df)\n",
    "    df = add_time_features(df)\n",
    "    df.to_csv(\"SFT_clean_data.csv\", index=False)\n",
    "    print(\"Data cleaned and saved to 'cleaned_fashion_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b26b02-701f-41d3-b015-dd5d02b2ada5",
   "metadata": {},
   "source": [
    "3. Aggregate the trends based on monthly data so it will be easier to determine the popularity of items. Use up to 2 trends to train the ARIMA model (the same trends should be used on LSTM but that comes with additional data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc0cc3-c707-46e1-ad27-234b7d7582ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/mnt/data/SFT_clean_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['year'] = pd.to_datetime(df['time'], errors='coerce').dt.year\n",
    "\n",
    "trends = [\"zara dress\", \"boots\", \"oversized blazer\", \"denim jacket\"]\n",
    "\n",
    "df['tags'] = df['tags'].fillna(\"\").str.lower()\n",
    "\n",
    "trend_counts = {trend: [] for trend in trends}\n",
    "years = sorted(df['year'].dropna().unique())\n",
    "\n",
    "for year in years:\n",
    "    df_year = df[df['year'] == year]\n",
    "    for trend in trends:\n",
    "        count = df_year['tags'].str.contains(trend, case=False, na=False).sum()\n",
    "        trend_counts[trend].append(count)\n",
    "\n",
    "trend_df = pd.DataFrame(trend_counts, index=years)\n",
    "trend_df.index.name = \"Year\"\n",
    "\n",
    "trend_df.reset_index(inplace=True)\n",
    "print(trend_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2452ac-4173-4fea-886d-b646aac96025",
   "metadata": {},
   "source": [
    "4. Check per month. The dataset has no missing values for time/there is no need to imputate any values. There is 1,636,496 rows of data. I chose to analyse 4 main trends I noticed when I briefly skimmed the dataset (e.g., denim jacket, boots, chanel bag, zara dress). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805a8f1-76f5-41ad-a023-cdc7152ae373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/mnt/data/SFT_clean_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['parsed_time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "df['month'] = df['parsed_time'].dt.to_period('M').astype(str)\n",
    "\n",
    "trends = [\"zara dress\", \"boots\", \"chanel bag\", \"denim jacket\"]\n",
    "\n",
    "df['tags'] = df['tags'].fillna(\"\").str.lower()\n",
    "\n",
    "trend_counts = {trend: [] for trend in trends}\n",
    "months = sorted(df['month'].dropna().unique())\n",
    "\n",
    "for month in months:\n",
    "    df_month = df[df['month'] == month]\n",
    "    for trend in trends:\n",
    "        count = df_month['tags'].str.contains(trend, case=False, na=False).sum()\n",
    "        trend_counts[trend].append(count)\n",
    "\n",
    "trend_df = pd.DataFrame(trend_counts, index=months)\n",
    "trend_df.index.name = \"Month\"\n",
    "\n",
    "trend_df.reset_index(inplace=True)\n",
    "print(trend_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02eff7-025a-4ef0-af4e-c46ef3220170",
   "metadata": {},
   "source": [
    "5. After computing a new dataset, I made line plots for all the four trends to compare them for the descriptive statististics part of the results section. Keep in mind I only need 2 trends to train both the ARIMA and LSTM so I am comparing the line curves between all to check which one resembles the product lifecycle curve most accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82efc1-764e-466b-b092-0f484951c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = \"SFT_clean_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['parsed_time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "df['month'] = df['parsed_time'].dt.to_period('M').astype(str)\n",
    "\n",
    "trends = [\"zara dress\", \"boots\", \"chanel bag\", \"denim jacket\"]\n",
    "\n",
    "df['tags'] = df['tags'].fillna(\"\").str.lower()\n",
    "\n",
    "trend_counts = {trend: [] for trend in trends}\n",
    "months = sorted(df['month'].dropna().unique())\n",
    "\n",
    "for month in months:\n",
    "    df_month = df[df['month'] == month]\n",
    "    for trend in trends:\n",
    "        count = df_month['tags'].str.contains(trend, case=False, na=False).sum()\n",
    "        trend_counts[trend].append(count)\n",
    "\n",
    "trend_df = pd.DataFrame(trend_counts, index=months)\n",
    "trend_df.index.name = \"Month\"\n",
    "trend_df.reset_index(inplace=True)\n",
    "trend_df.to_csv(\"trend_counts_over_time.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for trend in trends:\n",
    "    plt.plot(trend_df[\"Month\"], trend_df[trend], label=trend, linewidth=2)\n",
    "\n",
    "plt.title(\"Fashion Trends Over Time\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Mentions in Tags\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"fashion_trends_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Trend counts saved to 'trend_counts_over_time.csv'\")\n",
    "print(\"Plot saved as 'fashion_trends_plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120644d6-3bff-461c-822a-8edc750603d7",
   "metadata": {},
   "source": [
    "6. descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe4cf8-b9c8-478c-857b-acd3c32bf811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"trend_counts_over_time.csv\"  # Update this path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "desc_stats = df[['zara dress', 'chanel bag']].describe().T\n",
    "\n",
    "desc_stats['median'] = df[['zara dress', 'chanel bag']].median()\n",
    "desc_stats['mode'] = df[['zara dress', 'chanel bag']].mode().iloc[0]\n",
    "\n",
    "desc_stats = desc_stats[['count', 'mean', 'std', 'min', '25%', '50%', 'median', 'mode', '75%', 'max']]\n",
    "\n",
    "desc_stats = desc_stats.round(2)\n",
    "\n",
    "desc_stats.to_csv(\"descriptive_stats.csv\", index=False)\n",
    "\n",
    "print(\"Descriptive Statistics Table:\")\n",
    "print(desc_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177a161-b068-4859-8101-928caff3a23b",
   "metadata": {},
   "source": [
    "7. Run ADF test to check stationarity and then differenciate data (also fixed format of month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81be5a1-7bf5-47b2-bd32-4cca5f0144a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "df = pd.read_csv(\"trend_counts_over_time.csv\")\n",
    "\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "\n",
    "def adf_test(series, name):\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    print(f'ADF Test for \"{name}\"')\n",
    "    print(f'  ADF Statistic: {result[0]:.4f}')\n",
    "    print(f'  p-value: {result[1]:.4f}')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'     Critical Value ({key}): {value:.4f}')\n",
    "    print('  =>', 'Stationary' if result[1] <= 0.05 else 'Non-stationary')\n",
    "    print('-' * 40)\n",
    "\n",
    "for column in df.columns:\n",
    "    adf_test(df[column], column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32755517-c830-4c80-8b81-eb03192b817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"trend_counts_over_time.csv\")\n",
    "\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "\n",
    "df_diff = df.diff().dropna()\n",
    "\n",
    "df_diff.to_csv(\"trend_counts_differenced.csv\")\n",
    "\n",
    "print(\"Differenced dataset saved to 'trend_counts_differenced.csv'\")\n",
    "print(df_diff.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6656c6-96ce-4910-a3a4-0088a03a0c6d",
   "metadata": {},
   "source": [
    "8. Finding the outfits most popular location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478bc47e-e769-48cd-9bd7-dedf20b13076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('SFS_metadata.csv') \n",
    "\n",
    "df['tags'] = df['tags'].astype(str).str.lower()\n",
    "df['user_name'] = df['user_name'].astype(str)\n",
    "df['location'] = df['location'].astype(str)\n",
    "\n",
    "zara_rows = df[df['tags'].str.contains('zara dress', na=False)]\n",
    "chanel_rows = df[df['tags'].str.contains('chanel bag', na=False)]\n",
    "\n",
    "top_locations_zara = zara_rows['location'].value_counts().head(3)\n",
    "top_locations_chanel = chanel_rows['location'].value_counts().head(3)\n",
    "\n",
    "print(\"Zara dress photo locations (Top 3):\")\n",
    "print(top_locations_zara)\n",
    "\n",
    "print(\"Chanel bag photo locations (Top 3):\")\n",
    "print(top_locations_chanel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7b027-7c51-42f1-b88a-7394738853f5",
   "metadata": {},
   "source": [
    "9. Clean weather dataset for California and Aggregate the columns temperature and rainfall to get an average monthly number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d4b40-76f5-457f-84e7-6444e0f912d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'California_weather.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, skiprows=1, delimiter=';')\n",
    "\n",
    "df['dt_iso'] = df['dt_iso'].str.replace(' UTC', '', regex=False)\n",
    "df['dt_iso'] = pd.to_datetime(df['dt_iso'])\n",
    "\n",
    "df['rain_1h'] = df['rain_1h'].fillna(0)\n",
    "\n",
    "df['year_month'] = df['dt_iso'].dt.to_period('M')\n",
    "\n",
    "monthly_df = df.groupby('year_month').agg({\n",
    "    'temp': 'mean',\n",
    "    'rain_1h': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_df.rename(columns={'temp': 'avg_monthly_temp', 'rain_1h': 'avg_monthly_rain'}, inplace=True)\n",
    "monthly_df.to_csv('monthly_temp_rain.csv', index=False)\n",
    "\n",
    "print(monthly_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d5414-68aa-439b-917f-0725566779c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "monthly_df = pd.read_csv('monthly_temp_rain.csv')\n",
    "\n",
    "monthly_df['year_month'] = monthly_df['year_month'].astype(str)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(monthly_df['year_month'], monthly_df['avg_monthly_temp'], label='Avg Monthly Temp (Â°C)', marker='o')\n",
    "\n",
    "plt.plot(monthly_df['year_month'], monthly_df['avg_monthly_rain'], label='Avg Monthly Rain (mm)', marker='s')\n",
    "\n",
    "plt.title('Average Monthly Temperature and Rainfall in California')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f715c4-78d5-4fb5-9443-9eca6a12d4f5",
   "metadata": {},
   "source": [
    "10. 4-week moving average to smooth out the noise in Google Trends data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e7c6f-8bb9-4448-b9b0-7993699439a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('google_trends.csv', skiprows=1, delimiter=';')\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "\n",
    "df['Zara_MA'] = df['Zara Dress'].rolling(window=4).mean()\n",
    "df['Chanel_MA'] = df['Chanel Bag'].rolling(window=4).mean()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.plot(df['Month'], df['Zara Dress'], label='Zara Dress (Original)', alpha=0.3, color='blue')\n",
    "plt.plot(df['Month'], df['Zara_MA'], label='Zara Dress (4-Month MA)', linewidth=2.5, color='blue')\n",
    "\n",
    "plt.plot(df['Month'], df['Chanel Bag'], label='Chanel Bag (Original)', alpha=0.3, color='green')\n",
    "plt.plot(df['Month'], df['Chanel_MA'], label='Chanel Bag (4-Month MA)', linewidth=2.5, color='green')\n",
    "\n",
    "plt.title('Google Trends: Zara Dress vs Chanel Bag (4-Month Moving Average)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Search Interest')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb25bd9-4d8e-419e-a969-9559e2657733",
   "metadata": {},
   "source": [
    "11. Merged all of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ca8c6-9e82-4b14-844e-5157dcc43d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gt_df = pd.read_csv('google_trends.csv', skiprows=1, delimiter=';')\n",
    "weather_df = pd.read_csv('monthly_temp_rain.csv')\n",
    "sft_df = pd.read_csv('trend_counts_over_time.csv')\n",
    "\n",
    "gt_df['Month'] = pd.to_datetime(gt_df['Month'])\n",
    "weather_df['year_month'] = pd.to_datetime(weather_df['year_month'].astype(str))\n",
    "sft_df['Month'] = pd.to_datetime(sft_df['Month'])\n",
    "\n",
    "weather_df.rename(columns={'year_month': 'Month'}, inplace=True)\n",
    "gt_df.rename(columns={'Zara Dress': 'Zara Dress Search Interest', 'Chanel Bag': 'Chanel Bag Search Interest'}, inplace=True)\n",
    "\n",
    "merged_df = pd.merge(gt_df, weather_df, on='Month', how='inner')\n",
    "merged_df = pd.merge(merged_df, sft_df, on='Month', how='inner')\n",
    "\n",
    "merged_df.to_csv('merged_data.csv', index= False)\n",
    "\n",
    "print(merged_df.head())\n",
    "print(\"Saved as 'merged_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68780236-e4cf-418e-b587-72d3a4405e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gt_df = pd.read_csv('google_trends.csv', skiprows=1, delimiter=';')\n",
    "sft_df = pd.read_csv('trend_counts_over_time.csv')\n",
    "\n",
    "gt_df['Month'] = pd.to_datetime(gt_df['Month'])\n",
    "sft_df['Month'] = pd.to_datetime(sft_df['Month'])\n",
    "\n",
    "gt_df.rename(columns={'Zara Dress': 'Zara Dress Search Interest', 'Chanel Bag': 'Chanel Bag Search Interest'}, inplace=True)\n",
    "\n",
    "merged_df = pd.merge(merged_df, sft_df, on='Month', how='inner')\n",
    "\n",
    "merged_df.to_csv('merged_data_no_weather.csv', index= False)\n",
    "\n",
    "print(merged_df.head())\n",
    "print(\"Saved as 'merged_data_no_weather.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ad5e0-3c86-455d-9986-a629a0f42ca5",
   "metadata": {},
   "source": [
    "12. LSTM on all merged data (Zara Dress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1ecd5-b76c-4a80-8283-83a6123a5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"merged_data.csv\")\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df = df.asfreq('MS')\n",
    "\n",
    "features = ['Zara Dress Search Interest', 'Chanel Bag Search Interest', 'avg_monthly_temp', 'avg_monthly_rain']\n",
    "target = 'zara dress'\n",
    "\n",
    "cutoff_date = pd.Timestamp('2013-10-01')\n",
    "train_df = df[df.index < cutoff_date]\n",
    "test_df = df[df.index >= cutoff_date]\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(train_df[features])\n",
    "y_train_scaled = scaler_y.fit_transform(train_df[[target]])\n",
    "X_test_scaled = scaler_X.transform(test_df[features])\n",
    "y_test_scaled = scaler_y.transform(test_df[[target]])\n",
    "\n",
    "def create_sequences(X, y, seq_length=6):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 6\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape=(seq_length, len(features))))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=8, verbose=1)\n",
    "\n",
    "y_pred_scaled = model.predict(X_test_seq)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "forecast_dates = test_df.index[seq_length: seq_length + len(y_pred)]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df.index, df[target], label='Actual (Merged Data)', color='black')\n",
    "plt.plot(forecast_dates, y_pred.flatten(), label='LSTM Forecast', linestyle='--', color='red')\n",
    "plt.title(f\"LSTM Forecast on Merged Dataset: {target.title()}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Trend Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"LSTM RMSE on merged data: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8387ce-cb5c-48ec-b2b7-08e26d856919",
   "metadata": {},
   "source": [
    "13. LSTM on merged data with no weather (Zara dress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba90d94-1406-4c02-b618-0ec8b5e1f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"merged_data_no_weather.csv\")\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df = df.asfreq('MS')\n",
    "\n",
    "features = ['Zara Dress Search Interest', 'Chanel Bag Search Interest']\n",
    "target = 'zara dress'\n",
    "\n",
    "cutoff_date = pd.Timestamp('2013-10-01')\n",
    "train_df = df[df.index < cutoff_date]\n",
    "test_df = df[df.index >= cutoff_date]\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(train_df[features])\n",
    "y_train_scaled = scaler_y.fit_transform(train_df[[target]])\n",
    "X_test_scaled = scaler_X.transform(test_df[features])\n",
    "y_test_scaled = scaler_y.transform(test_df[[target]])\n",
    "\n",
    "def create_sequences(X, y, seq_length=6):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 6\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape=(seq_length, len(features))))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=8, verbose=1)\n",
    "\n",
    "y_pred_scaled = model.predict(X_test_seq)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "forecast_dates = test_df.index[seq_length: seq_length + len(y_pred)]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df.index, df[target], label='Actual (Merged Data)', color='black')\n",
    "plt.plot(forecast_dates, y_pred.flatten(), label='LSTM Forecast', linestyle='--', color='red')\n",
    "plt.title(f\"LSTM Forecast on Merged Dataset: {target.title()}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Trend Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"LSTM RMSE on merged data: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a00b966-c6b0-48fe-b3ca-21c0c288a86c",
   "metadata": {},
   "source": [
    "14. LSTM on only SFS dataset (Zara dress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633223e2-9231-4346-b926-0ebfd6571ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"trend_counts_over_time.csv\")\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df = df.asfreq('MS')\n",
    "\n",
    "features = ['zara dress', 'chanel bag']\n",
    "target = 'zara dress'\n",
    "\n",
    "cutoff_date = pd.Timestamp('2013-10-01')\n",
    "train_df = df[df.index < cutoff_date]\n",
    "test_df = df[df.index >= cutoff_date]\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(train_df[features])\n",
    "y_train_scaled = scaler_y.fit_transform(train_df[[target]])\n",
    "X_test_scaled = scaler_X.transform(test_df[features])\n",
    "y_test_scaled = scaler_y.transform(test_df[[target]])\n",
    "\n",
    "def create_sequences(X, y, seq_length=6):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 6\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape=(seq_length, len(features))))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=8, verbose=1)\n",
    "\n",
    "y_pred_scaled = model.predict(X_test_seq)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "forecast_dates = test_df.index[seq_length: seq_length + len(y_pred)]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df.index, df[target], label='Actual (Merged Data)', color='black')\n",
    "plt.plot(forecast_dates, y_pred.flatten(), label='LSTM Forecast', linestyle='--', color='red')\n",
    "plt.title(f\"LSTM Forecast on Merged Dataset: {target.title()}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Trend Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"LSTM RMSE on data: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b204c-6c5c-441a-aeba-d3fe809a2dfa",
   "metadata": {},
   "source": [
    "15. LSTM on all merged data (Chanel bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70efe07-a942-418a-b5e1-1c3797abbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"merged_data.csv\")\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df = df.asfreq('MS')\n",
    "\n",
    "features = ['Zara Dress Search Interest', 'Chanel Bag Search Interest', 'avg_monthly_temp', 'avg_monthly_rain']\n",
    "target = 'chanel bag'\n",
    "\n",
    "cutoff_date = pd.Timestamp('2014-05-01')\n",
    "train_df = df[df.index < cutoff_date]\n",
    "test_df = df[df.index >= cutoff_date]\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(train_df[features])\n",
    "y_train_scaled = scaler_y.fit_transform(train_df[[target]])\n",
    "X_test_scaled = scaler_X.transform(test_df[features])\n",
    "y_test_scaled = scaler_y.transform(test_df[[target]])\n",
    "\n",
    "def create_sequences(X, y, seq_length=6):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 6\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape=(seq_length, len(features))))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=8, verbose=1)\n",
    "\n",
    "y_pred_scaled = model.predict(X_test_seq)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "forecast_dates = test_df.index[seq_length: seq_length + len(y_pred)]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df.index, df[target], label='Actual (Merged Data)', color='black')\n",
    "plt.plot(forecast_dates, y_pred.flatten(), label='LSTM Forecast', linestyle='--', color='red')\n",
    "plt.title(f\"LSTM Forecast on Merged Dataset: {target.title()}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Trend Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"LSTM RMSE on merged data: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2359996-cea7-454a-9203-91fe61f0f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"merged_data_no_weather.csv\")\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df = df.asfreq('MS')\n",
    "\n",
    "features = ['Zara Dress Search Interest', 'Chanel Bag Search Interest']\n",
    "target = 'chanel bag'\n",
    "\n",
    "cutoff_date = pd.Timestamp('2014-05-01')\n",
    "train_df = df[df.index < cutoff_date]\n",
    "test_df = df[df.index >= cutoff_date]\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(train_df[features])\n",
    "y_train_scaled = scaler_y.fit_transform(train_df[[target]])\n",
    "X_test_scaled = scaler_X.transform(test_df[features])\n",
    "y_test_scaled = scaler_y.transform(test_df[[target]])\n",
    "\n",
    "def create_sequences(X, y, seq_length=6):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 6\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape=(seq_length, len(features))))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=8, verbose=1)\n",
    "\n",
    "y_pred_scaled = model.predict(X_test_seq)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "forecast_dates = test_df.index[seq_length: seq_length + len(y_pred)]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df.index, df[target], label='Actual (Merged Data)', color='black')\n",
    "plt.plot(forecast_dates, y_pred.flatten(), label='LSTM Forecast', linestyle='--', color='red')\n",
    "plt.title(f\"LSTM Forecast on Merged Dataset: {target.title()}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Trend Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"LSTM RMSE on merged data: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df826b-179e-44ea-8652-4f47e48a820d",
   "metadata": {},
   "source": [
    "16. LSTM on merged data with no weather (Chanel bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae298f-0bef-48d9-a159-919dc09cb7e6",
   "metadata": {},
   "source": [
    "17. LSTM on only SFS dataset (Chanel bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194219a-9ea4-45bb-8f6a-cdf4b28426b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"trend_counts_over_time.csv\")\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df = df.asfreq('MS')\n",
    "\n",
    "features = ['zara dress', 'chanel bag']\n",
    "target = 'chanel bag'\n",
    "\n",
    "cutoff_date = pd.Timestamp('2014-05-01')\n",
    "train_df = df[df.index < cutoff_date]\n",
    "test_df = df[df.index >= cutoff_date]\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(train_df[features])\n",
    "y_train_scaled = scaler_y.fit_transform(train_df[[target]])\n",
    "X_test_scaled = scaler_X.transform(test_df[features])\n",
    "y_test_scaled = scaler_y.transform(test_df[[target]])\n",
    "\n",
    "def create_sequences(X, y, seq_length=6):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 6\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape=(seq_length, len(features))))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=8, verbose=1)\n",
    "\n",
    "y_pred_scaled = model.predict(X_test_seq)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "forecast_dates = test_df.index[seq_length: seq_length + len(y_pred)]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df.index, df[target], label='Actual (Merged Data)', color='black')\n",
    "plt.plot(forecast_dates, y_pred.flatten(), label='LSTM Forecast', linestyle='--', color='red')\n",
    "plt.title(f\"LSTM Forecast on Merged Dataset: {target.title()}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Trend Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"LSTM RMSE on data: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95057784-38a2-401a-85ca-338d0c1e1404",
   "metadata": {},
   "source": [
    "18. ARIMA on Zara dress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd77c62-6a50-4101-8c67-6f8030282a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "\n",
    "df = pd.read_csv(\"trend_counts_over_time.csv\")\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df = df.asfreq('MS')\n",
    "\n",
    "target = 'zara dress'\n",
    "\n",
    "cutoff_date = pd.Timestamp('2013-10-01')\n",
    "train = df[target][:cutoff_date - pd.DateOffset(months=1)]\n",
    "test = df[target][cutoff_date:]\n",
    "\n",
    "model = ARIMA(train, order=(1, 1, 1))\n",
    "fitted = model.fit()\n",
    "\n",
    "forecast = fitted.forecast(steps=len(test))\n",
    "\n",
    "y_test_actual = test\n",
    "y_pred = forecast\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred))\n",
    "mae = mean_absolute_error(y_test_actual, y_pred)\n",
    "\n",
    "print(f\"ARIMA RMSE: {rmse:.2f}\")\n",
    "print(f\"ARIMA MAE:  {mae:.2f}\")\n",
    "\n",
    "summary_df = fitted.summary().tables[1]\n",
    "html_str = summary_df.as_html()\n",
    "summary_df_as_df = pd.read_html(StringIO(html_str), header=0, index_col=0)[0]\n",
    "summary_df_as_df.to_csv(\"arima_output_chanel.csv\")\n",
    "\n",
    "print(fitted.summary())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df[target], label='Actual (SFT Dataset)', color='black')\n",
    "plt.plot(test.index, forecast, label='ARIMA Forecast', linestyle='--', color='red')\n",
    "plt.title(f\"Forecasting Saturation: {target.title()} (ARIMA)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Trend Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910fedc7-5e98-452e-b4dc-e7ac2460b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SARIMAX Results                                \n",
    "==============================================================================\n",
    "Dep. Variable:             zara dress   No. Observations:                   67\n",
    "Model:                 ARIMA(1, 1, 1)   Log Likelihood                -344.639\n",
    "Date:                Wed, 30 Apr 2025   AIC                            695.277\n",
    "Time:                        12:57:51   BIC                            701.846\n",
    "Sample:                    03-01-2008   HQIC                           697.873\n",
    "                         - 09-01-2013                                         \n",
    "Covariance Type:                  opg                                         \n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "ar.L1          0.0427      0.197      0.217      0.828      -0.343       0.429\n",
    "ma.L1         -0.5734      0.155     -3.707      0.000      -0.877      -0.270\n",
    "sigma2      1999.0356    388.290      5.148      0.000    1238.002    2760.069\n",
    "===================================================================================\n",
    "Ljung-Box (L1) (Q):                   0.08   Jarque-Bera (JB):                 1.13\n",
    "Prob(Q):                              0.78   Prob(JB):                         0.57\n",
    "Heteroskedasticity (H):               4.15   Skew:                            -0.30\n",
    "Prob(H) (two-sided):                  0.00   Kurtosis:                         2.81\n",
    "===================================================================================\n",
    "\n",
    "Warnings:\n",
    "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29326c83-39b2-4abc-a466-51424ed40386",
   "metadata": {},
   "outputs": [],
   "source": [
    "19. ARIMA on Chanel bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ce56e-ee8c-459e-be4f-f62a6416985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "\n",
    "df = pd.read_csv(\"trend_counts_over_time.csv\")\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df = df.asfreq('MS')\n",
    "\n",
    "target = 'chanel bag'\n",
    "\n",
    "cutoff_date = pd.Timestamp('2014-05-01')\n",
    "train = df[target][:cutoff_date - pd.DateOffset(months=1)]\n",
    "test = df[target][cutoff_date:]\n",
    "\n",
    "model = ARIMA(train, order=(1, 1, 1))\n",
    "fitted = model.fit()\n",
    "\n",
    "forecast = fitted.forecast(steps=len(test))\n",
    "\n",
    "y_test_actual = test\n",
    "y_pred = forecast\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred))\n",
    "mae = mean_absolute_error(y_test_actual, y_pred)\n",
    "\n",
    "print(f\"ARIMA RMSE: {rmse:.2f}\")\n",
    "print(f\"ARIMA MAE:  {mae:.2f}\")\n",
    "\n",
    "summary_df = fitted.summary().tables[1]\n",
    "html_str = summary_df.as_html()\n",
    "summary_df_as_df = pd.read_html(StringIO(html_str), header=0, index_col=0)[0]\n",
    "summary_df_as_df.to_csv(\"arima_output_chanel.csv\")\n",
    "\n",
    "print(fitted.summary())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df[target], label='Actual (SFT Dataset)', color='black')\n",
    "plt.plot(test.index, forecast, label='ARIMA Forecast', linestyle='--', color='red')\n",
    "plt.title(f\"Forecasting Saturation: {target.title()} (ARIMA)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Trend Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace7aa1-c051-4c34-83c8-12da22d9f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "                               SARIMAX Results                                \n",
    "==============================================================================\n",
    "Dep. Variable:             chanel bag   No. Observations:                   74\n",
    "Model:                 ARIMA(1, 1, 1)   Log Likelihood                -378.091\n",
    "Date:                Tue, 06 May 2025   AIC                            762.182\n",
    "Time:                        12:51:06   BIC                            769.053\n",
    "Sample:                    03-01-2008   HQIC                           764.920\n",
    "                         - 04-01-2014                                         \n",
    "Covariance Type:                  opg                                         \n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "ar.L1         -0.3972      0.195     -2.041      0.041      -0.779      -0.016\n",
    "ma.L1         -0.1486      0.176     -0.846      0.398      -0.493       0.196\n",
    "sigma2      1838.2442    299.737      6.133      0.000    1250.770    2425.719\n",
    "===================================================================================\n",
    "Ljung-Box (L1) (Q):                   0.24   Jarque-Bera (JB):                 0.09\n",
    "Prob(Q):                              0.62   Prob(JB):                         0.95\n",
    "Heteroskedasticity (H):               7.36   Skew:                            -0.01\n",
    "Prob(H) (two-sided):                  0.00   Kurtosis:                         3.17\n",
    "===================================================================================\n",
    "\n",
    "Warnings:\n",
    "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
